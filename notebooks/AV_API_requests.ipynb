{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"ALPHA_VANTAGE_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded API key: UX22I8KUVTLLRXFQ\n"
     ]
    }
   ],
   "source": [
    "# Debug: Print the API key to verify it's loaded correctly\n",
    "print(f\"Loaded API key: {api_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch news articles\n",
    "def fetch_news(api_key, keywords, from_date, to_date, page=1):\n",
    "    url = \"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        \"function\": \"NEWS_SENTIMENT\",\n",
    "        \"apikey\": api_key,\n",
    "        \"tickers\": keywords,\n",
    "        \"topics\": \"economy,financial_markets\",\n",
    "        \"time_from\": from_date,\n",
    "        \"time_to\": to_date,\n",
    "        \"sort\": \"LATEST\",\n",
    "        \"limit\": 200,\n",
    "        \"page\": page\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    try:\n",
    "        data = response.json()\n",
    "    except ValueError:\n",
    "        print(f\"Error decoding JSON for date range {from_date} to {to_date} on page {page}\")\n",
    "        return {}\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to collect a sample of articles within a date range for given keywords\n",
    "def collect_sample_articles(keywords, from_date, to_date, max_articles=5):\n",
    "    all_articles = []\n",
    "    requests_made = 0\n",
    "    articles_per_request = 10  # Maximum articles per request\n",
    "\n",
    "    page = 1\n",
    "\n",
    "    while requests_made < max_articles // articles_per_request:\n",
    "        news_data = fetch_news(api_key, keywords, from_date, to_date, page)\n",
    "        \n",
    "        # Debug: Print the raw response for debugging\n",
    "        print(f\"Response for {from_date} to {to_date} on page {page}: {news_data}\")\n",
    "\n",
    "        # Check if there are articles in the response\n",
    "        if \"feed\" in news_data and news_data[\"feed\"]:\n",
    "            all_articles.extend(news_data[\"feed\"])\n",
    "            page += 1\n",
    "            requests_made += 1\n",
    "            sleep(12)  \n",
    "            \n",
    "            # Check if the sample limit is reached\n",
    "            if len(all_articles) >= max_articles:\n",
    "                return all_articles\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return all_articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date range for a smaller sample\n",
    "from_date = \"2023-01-01\"\n",
    "to_date = \"2023-12-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect a smaller sample of articles about economic factors\n",
    "economic_keywords = \"Inflation\"\n",
    "economic_articles = collect_sample_articles(economic_keywords, from_date, to_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect a smaller sample of articles about the S&P 500\n",
    "sp_keywords = \"SPY\"\n",
    "sp_articles = collect_sample_articles(sp_keywords, from_date, to_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert articles to DataFrames\n",
    "economic_df = pd.DataFrame(economic_articles)\n",
    "sp_df = pd.DataFrame(sp_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Economic Articles DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Total economic articles fetched: 0\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrames\n",
    "print(\"Economic Articles DataFrame:\")\n",
    "print(economic_df.head())\n",
    "print(f\"Total economic articles fetched: {len(economic_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S&P 500 Articles DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Total S&P 500 articles fetched: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nS&P 500 Articles DataFrame:\")\n",
    "print(sp_df.head())\n",
    "print(f\"Total S&P 500 articles fetched: {len(sp_df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance_sentiment_analysis-CghRMNpT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
